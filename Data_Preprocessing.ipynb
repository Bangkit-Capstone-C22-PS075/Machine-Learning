{"cells":[{"cell_type":"markdown","metadata":{"id":"DKd3jSDu2SHS"},"source":["# Dataset Preprocessing\n","This notebook include how we do dataset preprocessing from the existing dataset.\n","\n","\n","Link for the Dataset:\n","https://data.vision.ee.ethz.ch/cvl/lbossard/accv12/\n","\n","\n","Our raw dataset directory looks something like this:\n","\n","Images:\n","\n","*   0\n","*   1\n","*   2\n","*   etc.\n","\n","We want the final dataset directory to look something like this:\n","\n","Dataset:\n","\n","\n","*   Train\n","    *   0\n","    *   1\n","    *   2\n","    *   etc.\n","*   Test\n","\n","    *   0\n","    *   1\n","    *   2\n","    *   etc.\n","\n","Here is the original label of the dataset:\n","\n","*   0:  'blouses',\n","*   1:  'cloak',\n","*   2:  'coat',\n","*   3:  'jacket',\n","*   4:  'long dress',\n","*   5:  'polo shirt, sport shirt',\n","*   6:  'robe',\n","*   7:  'shirt',\n","*   8:  'short dress',\n","*   9:  'suit, suit of clothes',\n","*   10: 'sweater',\n","*   11: 'jersey, T-shirt, tee shirt',\n","*   12: 'undergarment, upper body',\n","*   14: 'vest, waistcoat',\n"]},{"cell_type":"markdown","metadata":{"id":"3ZJw2Uil4zMu"},"source":["# Import All Dependencies\n","Before run the code make sure you have all the dependencies and library needed."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZRtHfnh02Kfz"},"outputs":[],"source":["import os\n","import random\n","import shutil"]},{"cell_type":"markdown","metadata":{"id":"hFi1x9CU5ZHV"},"source":["# Create Folder for the New Dataset\n","We will create new folder based on our desired final directory"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bs3P4GAw8cHw"},"outputs":[],"source":["dataset_path= # set it to the new directory for the final dataset\n","# make the train and test folder\n","os.mkdir(os.path.join(dataset_path,\"train\"))\n","os.mkdir(os.path.join(dataset_path,\"test\"))\n","\n","folder_split=[\"train\",\"test\"]\n","# create the label list based on the dataset\n","sub_label=[\"0\" ,\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"10\",\"11\",\"12\",\"13\",\"14\"]\n","\n","# looping to create subfolder in each folder\n","for folder_name in folder_split:\n","    sub_path=os.path.join(dest_path,folder_name)\n","    os.mkdir(sub_path)\n","    for sub_folder in label:\n","        os.mkdir(os.path.join(sub_path,sub_folder))"]},{"cell_type":"markdown","metadata":{"id":"0EYUYdMDDWZL"},"source":["# Copy the Data to the New Directory\n","We will move the data from the original directory to the new directory.\n","Here we will choose randomly 600 images from the data set and split it to the training and test .\n","\n","Train will have 500 images and test have 100 images. Each image will be in format: 'label.num.jpg'. Where label is the label of the image and num is auto increased number from 0-599"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"u4htIMufDjNP"},"outputs":[],"source":["scr_path = # set to the path of the orignal dataset\n","label= os.listdir(scr_path)\n","\n","for folder_name in label:\n","    scr_image = os.path.join(scr_path,folder_name)\n","    dest_train = os.path.join(dest_path,\"train\")\n","    dest_test = os.path.join(dest_path, \"test\")\n","    image_list=random.sample(os.listdir(scr_image),num_image)\n","    i = 0\n","    for image in image_list:\n","        if i < num_train:\n","            dest_image = os.path.join(dest_train, folder_name)\n","            shutil.copy(os.path.join(scr_image, image), os.path.join(dest_image , folder_name+\".\"+str(i)+\".jpg\"))\n","        else:\n","            dest_image = os.path.join(dest_test, folder_name)\n","            shutil.copy(os.path.join(scr_image, image), os.path.join(dest_image, folder_name + \".\" + str(i) + \".jpg\"))\n","        i += 1"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyMgRh5Cnk5qAm7K6qF9khGv","name":"Data_Preprocessing.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
